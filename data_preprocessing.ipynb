{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddharamesh93/Omdena-Mental--Health-Project/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1aDgQt9Mp-f",
        "outputId": "a57e695d-d895-47a2-f590-b6806b3a1f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Pres1-eKM6Mm"
      },
      "outputs": [],
      "source": [
        "# read data from json file\n",
        "with open('r_anxietyHelp.json', 'r') as file:\n",
        "  data = json.load(file)\n",
        "# convert it into a dataframe\n",
        "df = pd.json_normalize(data)\n",
        "df.head()\n",
        "\n",
        "# process comments and body separately\n",
        "\n",
        "# convert comments to lowercase and removes special characters, URLs, HTML tags, punctuation\n",
        "# comments is a list of dictionaries, each dictionary representing a comment in the post. The keys of the dictionary are the different fields\n",
        "def cleanup_comments(comments):\n",
        "  for comment in comments:\n",
        "    # remove urls and html tags first\n",
        "    clean_comment = re.sub(r'<[^>]+>', '', comment['body']) # remove html\n",
        "    clean_comment = re.sub(r'http\\S+', '', clean_comment) # remove urls\n",
        "    # split comment into tokens\n",
        "    tokens = word_tokenize(clean_comment)\n",
        "    # convert each to lowercase and removes special characters\n",
        "    lowercase_tokens = [re.sub(r\"[^a-zA-Z0-9]\", \"\", token.lower()) for token in tokens]\n",
        "    # convert back to a sentence\n",
        "    comment['body'] = ' '.join(lowercase_tokens)\n",
        "    comment['body'] = ' '.join(comment['body'].split()) # remove extra whitespace\n",
        "  return comments\n",
        "\n",
        "# cleans up main text body\n",
        "def cleanup_body(body):\n",
        "   # remove urls and html tags first\n",
        "  clean_body = re.sub(r'<[^>]+>', '', body) # remove html\n",
        "  clean_body = re.sub(r'http\\S+', '', clean_body) # remove urls\n",
        "  # split body into tokens\n",
        "  tokens = word_tokenize(clean_body)\n",
        "  # convert to lowercase\n",
        "  lowercase_tokens = [re.sub(r\"[^a-zA-Z0-9]\", \"\", token.lower()) for token in tokens]\n",
        "  body = ' '.join(lowercase_tokens)\n",
        "  body = ' '.join(body.split())\n",
        "  return body"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for each row, perform cleanup on the comments in that row (applies function to each row)\n",
        "# create a new column with cleaned comments\n",
        "df['comments_cleaned'] = df['comments'].apply(cleanup_comments)\n",
        "\n",
        "# perform cleanup for the body for each row and create a new column with cleaned body\n",
        "df['body_cleaned'] = df['body'].apply(cleanup_body)"
      ],
      "metadata": {
        "id": "4szFzZF1Px-e"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjKx6VX2ZEkRJyPjkzIrq7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}